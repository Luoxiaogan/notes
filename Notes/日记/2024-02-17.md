目的是：依靠数值实验，去验证各项的收敛速度

> 理解 push-pull 方法背后的逻辑

对于使用**column-stochatic**的$B$的更新步骤$\mathbf{x}^{k+1}=B\mathbf{x}^k$，极限情况是
$$B_{\infty}\mathbf{x}=\pi_{r}\mathbb{1}_{n}^T \mathbf{x}=[\pi_{r},\dots,\pi_{r}] \begin{bmatrix}
\mathbf{x_{1}} \\
\vdots \\
\mathbf{x}_{n}
\end{bmatrix}=\sum_{i=1}^n \pi_{r}\mathbf{x}_{i}=\pi_{r}\sum_{i=1}^n\mathbf{x}_{i}$$
而想要的是
$$
\frac{1}{n}\mathbb{1}_{n}\mathbb{1}_{n}^T\mathbf{x}
$$
比较$\pi_{r}\mathbb{1}_{n}^T \mathbf{x}$和$\frac{1}{n}\mathbb{1}_{n}\mathbb{1}_{n}^T\mathbf{x}$，发现，后面的$\mathbb{1}_{n}^T\mathbf{x}=\sum_{i=1}^n \mathbf{x}_{i}$都是一样的，不同的是以$\pi_{r}$来分配权重和以$\frac{1}{n}\mathbb{1}_{n}$来分配权重

差距是
$$
\pi_{r}\mathbb{1}_{n}^T \mathbf{x}-\frac{1}{n}\mathbb{1}_{n}\mathbb{1}_{n}^T\mathbf{x}=(\pi_{r}-\frac{1}{n}\mathbb{1}_{n})\mathbb{1}_{n}^T\mathbf{x}
$$

+ push-sum 方法, **one-shot reweighting**
$$
\text{diag}(n\pi_{r})^{-1}\pi_{r}
=\frac{1}{n}\mathbb{1}_{n}$$
但是对于节点来说，它有可能不知道$\pi_{r}$，因此要构造一个辅助的迭代来逼近$\pi_{r}$，具体来说，就是
$$
v^{(0)} \in \mathbb{R}^n, \mathbb{1}_{n}^Tv^{(0)}=n
$$
那么通过迭代$v^{k+1}=Bv^{(k)}$，有
$$
v^{\infty}=B_{\infty}v^{(0)}=\pi_{r}\mathbb{1}_{n}^Tv^{(0)}=n\pi_{r}
$$
故而有push-sum algorithm:
$$
\begin{align}
\mathbf{x}^{k+1}&=B\mathbf{x}^{k} \\
v^{k+1}&=Bv^{k} \\
V^{k+1}&=\text{diag}(v^{k+1}) \\
\mathbf{w}^{k+1}&=(V^{k+1})^{-1}\mathbf{x}^{k+1}
\end{align}
$$
从而保证了
$$
\mathbf{w}^{\infty} \to \frac{1}{n}\mathbb{1}_{n}\mathbb{1}_{n}^T\mathbf{x}
$$

> Spectral gap

$\pi_{r}$替换了$\frac{1}{n}\mathbf{1}_{n}$，因此 spectral gap指标变成了
$$
1-\beta_{\pi_{l}}, \text{where}\;
\beta_{\pi_{r}}:=||  B-\pi_{r}\mathbb{1}_{n}^T||_{\pi_{r}}  \in[0,1)
$$
数值实验表明spectral gap : $1-\beta$越小，consensus error越小，因此spectral gap更小不一定表明更慢的信息扩散

> Equilibrium skewness

使用$\mathbf{w}^{k}=(V^{k})^{-1}\mathbf{x}^k$去逼近$\frac{1}{n}\mathbb{1}_{n}\mathbb{1}_{n}^T\mathbf{x}^0$
考虑error
$$
\begin{align}
&\mathbf{w}^k-\frac{1}{n}\mathbb{1}_{n}\mathbb{1}_{n}^T\mathbf{x}^0 \\
=&(\text{diag}(v^k))^{-1}B^k\mathbf{x}^0-\frac{1}{n}\mathbb{1}_{n}\mathbb{1}_{n}^T\mathbf{x}^0 \\
=&(\text{diag}(v^k))^{-1}B^k\mathbf{x}^0-\text{diag}(n\pi_{r})^{-1}\pi_{r}\mathbb{1}_{n}^T\mathbf{x}^0 \\
=&[(\text{diag}(v^k))^{-1}B^k-\text{diag}(n\pi_{r})^{-1}\pi_{r}\mathbb{1}_{n}^T]\mathbf{x}^0 \\
=&[(\text{diag}(B^kv^0))^{-1}B^k-\text{diag}(n\pi_{r})^{-1}\pi_{r}\mathbb{1}_{n}^T]\mathbf{x}^0
\end{align}
$$

但是$(\text{diag}(B^kv^0))^{-1}B^k$很难去处理

考虑特殊情况（或者说是，迭代次数k非常大的时候，$B^kv^0$十分接近$n\pi_{l}$），$v^0=n\pi_{l}$，那么$B^kv^0=B^kn\pi_{l}=n\pi_{l}$
此时error为
$$
\begin{align}
&[(\text{diag}(B^kv^0))^{-1}B^k-\text{diag}(n\pi_{r})^{-1}\pi_{r}\mathbb{1}_{n}^T]\mathbf{x}^0 \\
=&\text{diag}(n\pi_{r})^{-1}[B^k-\pi_{r}\mathbb{1}_{n}^T]\mathbf{x}^0 \\
=&\text{diag}(n\pi_{r})^{-1}(B-\pi_{r}\mathbb{1}_{n}^T)^k\mathbf{x}^0 
\end{align}
$$
最后一个等号是由于$(\pi_{r}\mathbf{1}_{n}^T)^2=\pi_{r}\underbrace{ (\mathbf{1}_{n}^T\pi_{r}) }_{ =1 } \mathbf{1}_{n}^T=\pi_{r}\mathbf{1}_{n}^T$
从而有
$$
\begin{align}
&||  \text{diag}(n\pi_{r})^{-1}(B-\pi_{r}\mathbb{1}_{n}^T)^k\mathbf{x}^0  ||_{F} ^2  \\
\leq &\sum_{i=1}^n  || \{\text{diag}(n\pi_{r})^{-1}(B-\pi_{r}\mathbb{1}_{n}^T)^k\mathbf{x}^0 \} _{i}||  _{2}^2 \\
\leq & 
\end{align}
$$



> 关于consensus的思考

我们的目标函数，比如说$\sum_{i=1}^n f_{i}(x)$，最后的optimum point $x^*$，应该是使得$\sum_{i=1}^n \nabla f_{i}(x^*)=0$的值，而实际上, consensus的意思是，我想要每一个节点的$x$的值都是想去拟合$x^*$，最终会达到consensus，即每一个节点上面的$x$都是一样的，那么就可以说
$$
\sum_{i=1}^n \nabla f_{i}(x_{i})=0, \forall i \in [ n]
$$




