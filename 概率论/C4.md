## 4.1数学期望

### 数学期望的两个直观理解：

+ 大量观测值的**时间平均**
+ 所有可能值的**加权平均**

### 离散型

$EX=\sum_kx_kp_k$，若$\sum_kx_kp_k < \infty$

+ 绝对收敛保证了换序不变
+ 正部：$x^+=x \vee 0$；负部：$x^-=(-x)\wedge 0$，对于$\sum_kx^+_kp_k, \sum_kx_k^-p_k$，一个收敛，一个发散，那么$EX=\sum_kx_kp_k$良定；两个均收敛，$EX=\sum_kx_kp_k=\sum_kx^+_kp_k-\sum_kx^-_kp_k$，期望存在
+ 数学期望是分布的数字特征，同分布的随机变量有相同的期望
+ 数学期望可以理解为“重心”

#### 需要熟悉并记住的例子：

> 1.**泊松分布**：$p_k=\frac{\lambda^k}{k!}e^{-\lambda}, k=0,1,...,n,...$
> $kp_k=k\frac{\lambda^k}{k!}e^{-\lambda}=\frac{\lambda^k}{(k-1)!}e^{-\lambda}=\lambda\frac{\lambda^{k-1}}{(k-1)!}e^{-\lambda}=\lambda p_{k-1},k=1,2,...$
> $EX=\sum_{k=0}^\infty kp_k=\sum_{k=1}^\infty \lambda p_{k-1}=\lambda$
> 2.**几何分布**：$P(X>n)=q^n,n\geq0,EX=\sum_{n=0}^\infty P(X> n)=\sum_{n=0}^\infty q^n=\frac{1}{1-q}=\frac{1}{p}$

#### 技术和技巧：

> 1.$X$取非负整数，那么$EX=\sum_{n=1}^\infty P(X\geq n)=\sum_{n=0}^\infty P(X> n)$
> 证明：$EX=\sum_{k=1}^\infty kp_k=\sum_{k=1} ^\infty \sum_{n=1}^k p_k=\sum_{n=1}^\infty \sum_{k=n}^\infty p_k=\sum_{n=1}^\infty P(X\geq n)$
>
> + 理解为一种换序，$\sum_{k=1}^\infty kp_k$是先对$k$个$p_k$求和，再对$k$求和；那么我可以先对$k$求和，得到$\sum_{k=n}^\infty p_k$，再对$n$求和
> + $\sum_{n=1}^\infty P(X\geq n)$是尾分布的求和
>
> 2.$X$为非负格点类型，取值是$0,\frac{1}{N},\frac{2}{N},...$，实际上就是同时除以了一个常数$N$，有$EX=\sum_{k=1}^\infty \frac{k}{N}p_k=\frac{1}{N}\sum_{k=1}^\infty kp_k=\frac{1}{N} \sum_{k=1} ^\infty \sum_{n=1}^k p_k=\frac{1}{N} \sum_{n=1}^\infty \sum_{k=n}^\infty p_k=\frac{1}{N}\sum_{n=0}^\infty P(X> \frac{k}{N})$
> 同样是尾分布的求和，不过除以了一个常数
>
> 因此，一个常用的技术就是在面对**定号的格点型分布**的时候，可以考虑**尾分布的求和**

### 连续型

$\sum x_i p(x_i) \Delta x_i \to \int xp(x)dx, EX=\int xp(x)dx$，若$\int |x|p(x)dx < \infty$

+ 绝对收敛同样保证了换序不变
+ 正部：$\int x^+p(x)dx=\int_0^\infty xp(x)dx$；负部:$\int x^-p(x)dx=\int_{-\infty}^0 xp(x)dx$. 一个收敛，一个发散，那么数学期望是良定的；两个均收敛，那么数学期望是存在的
+ 若分布函数是偶函数，那么它的数学期望要么是0，要么不存在，因此要去**验证绝对收敛性**

#### 需要熟悉并记住的例子：

> **指数分布**：$p(x)=\lambda e^{-\lambda x},x>0$，$EX=\int_0^\infty G(x)dx=\int_0^\infty e^{-\lambda x}dx=\frac{1}{\lambda}$

#### 技术和技巧：

> 与离散型平行的有：若$X\geq 0,EX=\int_0^\infty G(x)dx, G(x)$是尾分布
> 证明：$EX=\int_0 ^\infty xp(x)dx = \int_0 ^\infty x d(-G(x))=-xG(x)\big|_{0}^{\infty} +\int_0 ^\infty G(x)dx=\int_0 ^\infty G(x)dx$
>
> + 问题在于$xG(x)$在$x \to \infty$时是否为0，因为我只知道当$x \to \infty$时，$G(x)\to 0$，但是我不知道收敛于$0$的速度，因此要加条件（二选一）
> + 条件一： $\int_0 ^\infty xp(x)dx$收敛，那么$aG(x)\leq\int_a ^\infty xg(x)dx$，令$a \to \infty$， $aG(a) \to 0$
> + 条件二：$\int_0^\infty G(x)dx$收敛，那么$\frac{a}{2}G(a)\leq\int^a_{\frac{a}{2}}G(x)dx$，令$a \to \infty$， $aG(a) \to 0$
> + 连续型中的分部积分就是离散型中的求和号交换
> + $\int_0 ^\infty xp(x)dx$中，$p(x)dx=d(F(x))=d(-G(x))$，但很多时候尾分布更好用

**定号**的**连续型分布**，考虑对于**尾分布的积分**（验证一下收敛性）

### 一般情形

#### 第一种定义方式

**核心思想：无论是离散型的还是连续型的，我都去微调分布$X$，使得它调整为离散分点上的离散型随机变量，然后在去逼近**
假设$X\geq 0$，$Y=\frac{1}{n}[nX]$,相当于以$\frac{1}{n}$的长度去分划$(0,+\infty)$，$(\frac{k}{n},\frac{k+1}{n})$上的权重全部落在$\frac{k}{n}$处.
$|X-Y|\leq \frac{1}{n}$，故由数量期望观测值的时间平均的理解，$|EX-EY|\leq \frac{1}{n}$.
故而$EY=\sum_{k=0}^\infty \frac{k}{n}P(Y=\frac{k}{n}) =\sum_{k=1}^\infty \frac{k}{n}P(Y=\frac{k}{n})  =\sum_{k=1}^\infty \frac{1}{n}P(Y\geq \frac{k}{n})=\sum_{k=0}^\infty \frac{1}{n}P(Y> \frac{k}{n})=\sum_{k=0}^\infty \frac{1}{n}P(X>\frac{k}{n})\to \int_0^\infty G(x)dx$

故有$EX=\int_0^\infty G(x)dx$,若$X$定号

#### 第二种定义方式

操作同上，$EY=\sum_{k=0}^\infty \frac{k}{n}P(Y=\frac{k}{n}) =\sum_{k=0}^\infty \frac{k}{n}P(\frac{k}{n} \leq X <\frac{k+1}{n}) =\sum_{k=0}^\infty \frac{k}{n} (F(\frac{k+1}{n})-F(\frac{k}{n})) \to \int_0^\infty xdF(x)$

#### 第三种定义方式

**Lebesgue-Stieltjes 积分**：$\int x dF(x)=\lim_{\Delta \to 0} \sum_i x_i (F(x_{i+1})-F(x_i))$，$EX=\int x dF(x)$，若$\int |x| dF(x) < \infty$

#### 计算方法（还是尾分布积分好用）
已知：$X\geq 0, EX=\int_0^\infty G(x)dx=\int_0 ^\infty P(X>x)dx=\int_0^\infty P(X\geq x)dx$

因此，可以把分布$X$拆分成大于零和小于零的两部分用尾分布函数的积分去计算：
$EX=\int_0^\infty P(X>x)dx - \int_{-\infty}^0 P(X\leq x)dx$


+ 取$> or \geq$是一样的，因为定积分中改变可列个点的取值是不会改变积分结果的
+ 期望$EX$存在$\iff EX^{\pm}<\infty \iff E|X| <\infty \iff \int |x|dF(x) < \infty$
+ 若$X$有界，$P(|X|\leq M)=1$，那么期望$EX$必定存在（因为分成两部分的尾分布函数的积分积出来都是实数）

### 数学期望的性质